{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fbe02c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BeitFeatureExtractor, BeitForImageClassification, AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743fea15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\beit\\feature_extraction_beit.py:28: FutureWarning: The class BeitFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use BeitImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "train_df = pd.read_csv(train_csv)\n",
    "test_df = pd.read_csv(test_csv)\n",
    "submission_df = pd.read_csv(submission_csv)\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder() # 문자를 숫자로 수치화(beit모델특성)\n",
    "train_df['label'] = label_encoder.fit_transform(train_df['label'])\n",
    "\n",
    "# 데이터셋정의\n",
    "class CustomDataset(Dataset):  \n",
    "    def __init__(self, dataframe, feature_extractor, mode='train'):\n",
    "        self.dataframe = dataframe  \n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train': # train\n",
    "            img_path = self.dataframe.iloc[idx]['img_path']  \n",
    "            label = self.dataframe.iloc[idx]['label'] \n",
    "        else: #test \n",
    "            img_path = self.dataframe.iloc[idx]['img_path']  \n",
    "            label = -1  # test에는 label이 없으므로 더미레이블로 -1 사용\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\") \n",
    "        inputs = self.feature_extractor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "        if self.mode == 'train': #train \n",
    "            return inputs['pixel_values'].squeeze(0), torch.tensor(label, dtype=torch.long)          \n",
    "        else: #test\n",
    "            return inputs['pixel_values'].squeeze(0), self.dataframe.iloc[idx]['id']\n",
    "\n",
    "# Feature extractor\n",
    "feature_extractor = BeitFeatureExtractor.from_pretrained('microsoft/beit-base-patch16-224-pt22k')\n",
    "\n",
    "# 데이터셋 준비\n",
    "train_dataset = CustomDataset(train_df, feature_extractor, mode='train')\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True) # 배치사이즈16, 데이터 무작위로 섞어서 로드\n",
    "\n",
    "test_dataset = CustomDataset(test_df, feature_extractor, mode='test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False) # train은 성능향상과 균등한 학습을 위해 셔플 트루\n",
    "                                                    # 테스트는 디버깅 편의성을 위해(샘플에대한 모델을 쉽게 추적하기위해)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fb5fdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BeitForImageClassification were not initialized from the model checkpoint at microsoft/beit-base-patch16-224-pt22k and are newly initialized: ['beit.pooler.layernorm.bias', 'beit.pooler.layernorm.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\felic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 990/990 [06:08<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.5247640064494177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 990/990 [05:12<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.43669206224231405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 990/990 [05:03<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.24004388450353284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 990/990 [05:14<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.1505419069736481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 990/990 [05:14<00:00,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.10930087733731576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델준비\n",
    "model = BeitForImageClassification.from_pretrained('microsoft/beit-base-patch16-224-pt22k', num_labels=len(label_encoder.classes_))\n",
    "model.to('cuda') #gpu\n",
    "\n",
    "# 옵티마이저\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5) \n",
    "criterion = CrossEntropyLoss()  \n",
    "\n",
    "# 학습루프 \n",
    "epochs = 5 \n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in tqdm(train_loader):\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(pixel_values=inputs)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f966f8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96327f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 425/425 [00:53<00:00,  8.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# 평가, 예측\n",
    "model.eval()\n",
    "predictions = []\n",
    "ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        inputs, id_batch = batch\n",
    "        inputs = inputs.to('cuda')\n",
    "\n",
    "        outputs = model(pixel_values=inputs)\n",
    "        _, preds = torch.max(outputs.logits, dim=1)\n",
    "        \n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        ids.extend(id_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85b462e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과저장\n",
    "submission_df['label'] = label_encoder.inverse_transform(predictions) #inverse_transform 수치를 문자로 다시 변환\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdab5f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5520e6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 990/990 [02:03<00:00,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 98.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train 데이터 평가\n",
    "model.eval() \n",
    "train_predictions = []\n",
    "train_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(train_loader):  \n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "\n",
    "        outputs = model(pixel_values=inputs)\n",
    "        _, preds = torch.max(outputs.logits, dim=1)  # 예측결과\n",
    "        \n",
    "        train_predictions.extend(preds.cpu().numpy())\n",
    "        train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 정확도\n",
    "correct = sum(p == t for p, t in zip(train_predictions, train_labels))\n",
    "accuracy = correct / len(train_labels)\n",
    "print(f'Train Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c737b7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9860426929392446\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6012610f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
